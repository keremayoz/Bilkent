{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "test_feature = pd.read_csv(\"question-2-test-features.csv\", header=None)\n",
    "test_label = pd.read_csv(\"question-2-test-labels.csv\", header=None)\n",
    "train_feature = pd.read_csv(\"question-2-train-features.csv\", header=None)\n",
    "train_label = pd.read_csv(\"question-2-train-labels.csv\", header=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(array, count):\n",
    "    folds = []\n",
    "    size = np.shape(array)[0]\n",
    "    fold_size = int(size / count)\n",
    "    for i in range(10):\n",
    "        piece1 = array[0:i*fold_size]\n",
    "        piece2 = array[(i+1)*fold_size:size]\n",
    "        folds.append(np.concatenate((piece1,piece2)))\n",
    "    return np.array(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## TRAINING DATA PRE-PROCESSING ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain training data and label as whole\n",
    "x_train = train_feature.values\n",
    "y_train = train_label.values\n",
    "y_train[y_train < 190] = 0 \n",
    "y_train[y_train >= 190] = 1\n",
    "y_train = np.transpose(y_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data and label into folds\n",
    "x_train_folds = create_folds(x_train, 10)\n",
    "y_train_folds = create_folds(y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "singular_x_folds = np.array(np.split(x_train, 10))\n",
    "singular_y_folds = np.array(np.split(y_train,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain test data and label\n",
    "x_test = test_feature.values\n",
    "y_test = test_label.values\n",
    "y_test[y_test < 190] = 0 \n",
    "y_test[y_test >= 190] = 1\n",
    "y_test = np.transpose(y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################### LINEAR SVM ##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_interval = [0.001,0.01,0.1,1,10,100]\n",
    "gamma_interval = [1/16,1/8,1/4,1/2,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with different C values with 10-fold cross validation\n",
    "train_accuracy = np.zeros((len(C_interval),10))\n",
    "for c in range(len(C_interval)):\n",
    "    classifier = svm.LinearSVC(C=C_interval[c], random_state=0)\n",
    "    for i in range(10):\n",
    "        classifier.fit(x_train_folds[i], y_train_folds[i])\n",
    "        # Train prediction and accuracy\n",
    "        y_pred = classifier.predict(singular_x_folds[i])\n",
    "        train_accuracy[c][i] = np.sum(y_pred==singular_y_folds[i]) / len(singular_y_folds[i]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal C value\n",
    "training_mean_accuracy = np.mean(train_accuracy, axis=1)\n",
    "optimal_c = C_interval[np.argmax(training_mean_accuracy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71.05714286, 75.07142857, 75.32857143, 73.44285714, 65.88571429,\n",
       "       69.51428571])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 69.41977501480166\n"
     ]
    }
   ],
   "source": [
    "# Test prediction and accuracy\n",
    "classifier = svm.LinearSVC(C=optimal_c, random_state=0)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(x_test)\n",
    "test_accuracy = np.sum(y_pred==y_test) / len(y_test) * 100\n",
    "print(\"Test accuracy = \" + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 836\n",
      "True Negative: 1509\n",
      "False Positive: 104\n",
      "False Negative: 929\n",
      "Total = 3378\n",
      "\n",
      "Precision: 0.8893617021276595\n",
      "Recall: 0.4736543909348442\n",
      "NPV: 0.6189499589827727\n",
      "FPR: 0.06447613143211407\n",
      "FDR: 0.11063829787234042\n",
      "F1: 1.3049907578558226\n",
      "F2: 1.1031250000000001\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix values\n",
    "tp = int(np.sum(y_pred * y_test))\n",
    "tn = int(np.sum(y_pred+y_test==0))\n",
    "fp = int(np.sum(y_pred-y_test==1))\n",
    "fn = int(np.sum(y_test-y_pred==1))\n",
    "\n",
    "print(\"True Positive: \" + str(tp))\n",
    "print(\"True Negative: \" + str(tn))\n",
    "print(\"False Positive: \" + str(fp))\n",
    "print(\"False Negative: \" + str(fn))\n",
    "print(\"Total = \" + str(tp+fp+fn+tn))\n",
    "\n",
    "print()\n",
    "print(\"Precision: \" + str(tp/(tp+fp)))\n",
    "print(\"Recall: \" + str(tp/(tp+fn)))\n",
    "print(\"NPV: \" + str(tn/(tn+fn)))\n",
    "print(\"FPR: \" + str(fp/(fp+tn)))\n",
    "print(\"FDR: \" + str(fp/(tp+fp)))\n",
    "print(\"F1: \" + str((2*tp/(tp+fp))/(tp/(tp+fp)+tp/(tp+fn))))\n",
    "print(\"F2: \" + str((5*tp/(tp+fp))/(4*tp/(tp+fp)+tp/(tp+fn))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################### RBF SVM ##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with different C values with 10-fold cross validation\n",
    "train_accuracy_rbf = np.zeros((len(gamma_interval),10))\n",
    "for g in range(len(gamma_interval)):\n",
    "    classifier = svm.SVC(C=1e4,gamma=gamma_interval[g], kernel='rbf')\n",
    "    for i in range(10):\n",
    "        classifier.fit(x_train_folds[i], y_train_folds[i])\n",
    "        # Train prediction and accuracy\n",
    "        y_pred = classifier.predict(singular_x_folds[i])\n",
    "        train_accuracy_rbf[g][i] = np.sum(y_pred==singular_y_folds[i]) / len(singular_y_folds[i]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal gamma value\n",
    "training_mean_accuracy_rbf = np.mean(train_accuracy_rbf, axis=1)\n",
    "optimal_gamma = gamma_interval[np.argmax(training_mean_accuracy_rbf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy rbf = 70.54470100651274\n"
     ]
    }
   ],
   "source": [
    "# Test prediction and accuracy\n",
    "classifier = svm.SVC(C=1e4, gamma=optimal_gamma, kernel='linear')\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "test_accuracy = np.sum(y_pred==y_test) / len(y_test) * 100\n",
    "print(\"Test accuracy rbf = \" + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 843\n",
      "True Negative: 1540\n",
      "False Positive: 73\n",
      "False Negative: 922\n",
      "Total = 3378\n",
      "\n",
      "Precision: 0.9203056768558951\n",
      "Recall: 0.4776203966005666\n",
      "NPV: 0.6255077173030057\n",
      "FPR: 0.04525728456292622\n",
      "FDR: 0.07969432314410481\n",
      "F1: 1.3166728832525176\n",
      "F2: 1.1064443329989968\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix values\n",
    "tp = int(np.sum(y_pred * y_test))\n",
    "tn = int(np.sum(y_pred+y_test==0))\n",
    "fp = int(np.sum(y_pred-y_test==1))\n",
    "fn = int(np.sum(y_test-y_pred==1))\n",
    "\n",
    "print(\"True Positive: \" + str(tp))\n",
    "print(\"True Negative: \" + str(tn))\n",
    "print(\"False Positive: \" + str(fp))\n",
    "print(\"False Negative: \" + str(fn))\n",
    "print(\"Total = \" + str(tp+fp+fn+tn))\n",
    "\n",
    "print()\n",
    "print(\"Precision: \" + str(tp/(tp+fp)))\n",
    "print(\"Recall: \" + str(tp/(tp+fn)))\n",
    "print(\"NPV: \" + str(tn/(tn+fn)))\n",
    "print(\"FPR: \" + str(fp/(fp+tn)))\n",
    "print(\"FDR: \" + str(fp/(tp+fp)))\n",
    "print(\"F1: \" + str((2*tp/(tp+fp))/(tp/(tp+fp)+tp/(tp+fn))))\n",
    "print(\"F2: \" + str((5*tp/(tp+fp))/(4*tp/(tp+fp)+tp/(tp+fn))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
